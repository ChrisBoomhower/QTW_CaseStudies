---
title: "Simulation Study of a Branching Process - Case Study Unit 12"
output: html_notebook
---

#ASSIGNMENTS
* **Abstract, Background, Methods - Fisher**
* **Data Acquisition - Chris**
* **Define and Execute Test Simulations - Chris**
* **Analysis of Results (barplots) - Cory (Barplots look the same, and though many values are equal, they are different as they are designed to show different relationships based on generations and offspring. Alex will discuss the similarities and differences between each bar plot's values in his dumbbell plot section. You should interpret the plots at face value and reference Section 7.9.1 for guidance on interpretations. Please reach out on Slack with questions.)**
* **Analysis of Results (dumbbell plot [or table]) - Frye**
* **Discussion and Future Works - Fisher**

####Cory Adams, Chris Boomhower, Alexandra Fisher, Alex Frye
####MSDS 7333, November 26, 2017

***NOTE: We are answering Q.10 from the Data Science in R textbook (Pg. 307): "Carry out a simulation study to see if the re-parameterization suggested in Section 7.9.1 is appropriate. For example, fix kappa to be 1, and run the simulation for various values of lambda. Compare the results to other simulations where kappa is c not equal to 1, but the ratio of lambda/c matches one of the lambda values from the earlier simulation when kappa was 1."***


## Abstract


## Introduction
In this case study, we are studying how programs/jobs running on a CPU, or multiple CPUs in parallel, behave. Multiple CPUs running in parallel, known as parallel computing, enable us to break up programs into smaller portions that can run simultaneously on different CPUs. Specifically, we investigate the distribution of the completion time for the entire system to determine which combinations of job creation and job completion rates leads to processes that either never complete or definitely complete in finite time. 

To do this, we carry out a simulation study for the purpose of seeing if re-parameterization is appropriate. The branching process we investigate encompasses the same characteristics of the Aldous and Krebs process [3]. During the lifetime of a program/job, the number of births a job has is assumed to be from a Poisson distribution with expected count lambda. Also, the life length of each job is assumed to be from an exponential distribution with expected life length of 1/kappa. Lastly, each job can immediately start creating, or birthing, new jobs as soon as the job is generated, but the offspring/children cannot begin running until their parent finishes. The Monte Carlo method is used to simulate the process with different values for each job's expected lifetime (1/kappa) and number of jobs created per unit of time (lambda). 


## Background
John Tsitsiklis, Christos Papadimitriou, and Pierre Humblet studied how the systems of interdependent jobs behave in their study entitled “The Performance of a Precedence-Based Queuing Discipline” published in the Journal of the Association for Computing Machinery. In this paper, Tsitsiklis et. al. focused on finding the distribution of the length of time that a computational process, including all of its subtasks, takes to complete [2]. The overarching goal was to aid developers in designing code that could run efficiently while in parallel or queuing systems that could manage jobs on a compute cluster. To do this, a probability model was proposed for the generation of jobs and their associated interdependencies; however, using this system to answer questions of interest proved too challenging and mathematically difficult. 

David Aldous and William Krebs sought to overcome these issues via the use of a slightly different branching process, named the Aldous and Krebs process [3]. The Aldous and Krebs process is one in which: (1) the first job creates other jobs with time between start of jobs that is both independent and identically distributed, (2) the subsequent jobs generated must all wait until their parent program completes before they can actually run, and (3) each job can produce additional jobs of its own as soon as it is created so that it is not required to wait to start running before it can create another job. Through the study of this process, Aldous and Krebs were able to use mathematics to find analytic solutions to features of this process, just as Tsitsiklis et. al. had done. 

Tsitsiklis et. al. and Aldous and Krebs derived these solutions by studying ways to simplify more complex problems. Another way to do this would be via the use of simulations in place of or in addition to these closed-form analytic solutions because they may be overly cumbersome to solve mathematically. Simulations can also be useful for providing insight when we want to study the behavior of a process, but the assumed behavior is violated. In other words, simulation studies aim to model random processes via the use of a computer to gain deeper insights about associated properties. For the purposes of this study, the Monte Carlo method is used for simulation. 


## Methods
The steps used for this analysis were: 1) data acquisition; 2) defining and executing test simulations; 3) analysis of parameter results using bar plots; & 4) analysis of parameter results using dumbbell plot. 

*Note that code used includes modified versions of R code function examples found in Data Science in R: A Case Studies Approach to Computational Reasoning and Problem Solving, Chapter 7, pages 277-306 [1].*


## Results

### Data Acquisition
Before beginning our analysis and addressing the task at hand, we utilized methods provided in Chapter 7 of the *Data Science in R: A Case Studies Approach to Computational Reasoning and Problem Solving* textbook to generate the necessary functions and data needed for this study. As the purpose of this analysis is to research this data post load, we have excluded the text processing and feature engineering from this analysis. The data is loaded external to the notebook in the DataExtractAndClean.R file, allowing us to focus on our analysis of parameter ratios.
```{r echo=FALSE, message=FALSE, warning = FALSE}
# Load Libraries
library(scatterplot3d)
library(formattable)
library(ggplot2)
library(ggalt)
library(plotly)
library(stringr)
```

```{r include=FALSE, cache=TRUE, echo = FALSE, warning=FALSE}
source('DataExtractAndClean.R', echo = FALSE)
```

### Define and Execute Test Simulations
As our intention is to identify whether re-parameterization, as suggested in Section 7.9.1 of the textbook, is appropriate, we designed a series of simulations to evaluate outcomes using parameter combination groupings. While holding our kappa c value at 1, we varied the lambda values from 0.1 - 2.8, utilizing 10 unique lambda/kappa combinations in all. This allowed us to establish benchmark analyses to compare against in the next phase of our parameterization definitions.

The next phase consisted of extracting the ratio of lambda/c, where kappa is c=1, across all 10 combinations. These ratios were used to identify a valid combination of lambda and kappa values which produce the same ratio. We chose to assess two other lambda and kappa combinations for each of the 10 ratios where c=1. To simplify definitions, we always set the two additional parameterizations' lambda values to 0.5 and 1.5 while varying kappa values based on ratio.

After establishing our original 10 combinations while holding kappa c at a value of 1 and then generating two additional parameter combinations per each original combo, we had 30 different parameter combinations organized into 10 different ratio groupings. A table output generated by these combinations is shown with the parameter matrix code below. This table not only depicts the 30 combinations of lambda and kappa and their assocated ratio group number, but also depicts the lambda/c ratio value itself. Note that because derived kappa values (based on lambda/1 ratio value) were rounded to two decimal places, rounding error causes some minor difference in ratio values among parameter combinations in groups 03, 05, 06, 07, 08, and 10. These differences in ratio value prove negligible, however, as will be seen in the next subsection.
```{r}
new.lambdas = c(.1, .5, 1.5, 
                .4, .5, 1.5, 
                .7, .5, 1.5, 
                1.0, .5, 1.5, 
                1.3, .5, 1.5, 
                1.6, .5, 1.5, 
                1.9, .5, 1.5, 
                2.2, .5, 1.5, 
                2.5, .5, 1.5, 
                2.8, .5, 1.5)

#Kappas rounded to 2 decimals, thus rounding slightly skews ratios
new.kappas = c(1, 5, 15, 
               1, 1.25, 3.75, 
               1, 0.71, 2.14, 
               1, 0.5, 1.5, 
               1, 0.38, 1.15, 
               1, 0.31, 0.94, 
               1, 0.26, 0.79, 
               1, 0.23, 0.68, 
               1, 0.2, 0.6, 
               1, 0.18, 0.54)

new.ratio = format(new.lambdas/new.kappas, nsmall = 7)

new.paramGrid = as.matrix(cbind(new.lambdas, new.kappas))

ratio.groups <- rep(1:10, each = 3)
ratio.groups <- str_pad(ratio.groups, 2, pad = "0")

formattable(as.data.frame(cbind(ratio.groups, format(new.paramGrid, nsmall = 2), new.ratio)))
```

To speed up R notebook processing time, we also chose to save our simulation results to a .rds file for quick reload during subsequent notebook passes.
```{r}
if (!file.exists("newmcGridOutput.rds")){
  new.mcGrid = MCBA(params = new.paramGrid, repeats = 400, mG = 20, mO = 1000)
  saveRDS(new.mcGrid, "newmcGridOutput.rds")
}else{
  new.mcGrid = readRDS("newmcGridOutput.rds") 
}
```


### Analysis of Results
```{r}
mcGridAlive = sapply(new.mcGrid, function(oneParamSet) {
        sum((oneParamSet[1,] == 20) | (oneParamSet[2,] > 1000)) / 
            length(oneParamSet[2,]) })

test.names <- paste(new.lambdas, "/", new.kappas)
mcGridAlive.df <- as.data.frame(cbind(new.lambdas, new.kappas, test.names, new.ratio, mcGridAlive,
                                      ratio.groups))

mcGridAlive.plot <- ggplot(data=mcGridAlive.df, aes(x=test.names, y=mcGridAlive, fill=ratio.groups,
                                                    group=test.names)) +
    scale_x_discrete(limits=mcGridAlive.df$test.names) +
    geom_bar(stat="identity", position=position_dodge(), color="black") +
    labs(title = "Simulation Groups' Family Proportions Containing 20 Generations or 1000+ Offspring ",
         x = "Test Names Ordered by Parameter Simulation Groups", y = "Proportion") +
    theme(plot.title = element_text(size = 10.5), axis.text.x = element_text(angle = 90), legend.title = element_text(size = 10))

plot(mcGridAlive.plot)
```


```{r}
mcGridProp20kids = sapply(new.mcGrid, function(oneParamSet) {
    sum(oneParamSet[2,] > 19) / length(oneParamSet[2,]) })

test.names <- paste(new.lambdas, "/", new.kappas)
mcGridProp20kids.df <- as.data.frame(cbind(new.lambdas, new.kappas, test.names, new.ratio, mcGridProp20kids,
                                      ratio.groups))

mcGridProp20kids.plot <- ggplot(data=mcGridProp20kids.df, aes(x=test.names, y=mcGridProp20kids, fill=ratio.groups,
                                                    group=test.names)) +
    scale_x_discrete(limits=mcGridProp20kids.df$test.names) +
    geom_bar(stat="identity", position=position_dodge(), color="black") +
    labs(title = "Simulation Groups' Family Proportions Containing 20 Offspring ",
         x = "Test Names Ordered by Parameter Simulation Groups", y = "Proportion") +
    theme(plot.title = element_text(size = 13.5), axis.text.x = element_text(angle = 90), legend.title = element_text(size = 10))

plot(mcGridProp20kids.plot)
```

```{r}
mcGridAlive = sapply(new.mcGrid, function(oneParamSet) {
  sum((oneParamSet[1,] == 20) | (oneParamSet[2,] > 1000)) })
mcGridAlive = as.numeric(as.character(mcGridAlive))


mcGridProp20kids = sapply(new.mcGrid, function(oneParamSet) {
  sum(oneParamSet[2,] > 19)})
mcGridProp20kids = as.numeric(as.character(mcGridProp20kids))


df <- data.frame(test.names, mcGridAlive, mcGridProp20kids)

df$diff <- sprintf("+%d", as.numeric(mcGridProp20kids-mcGridAlive))
formattable(df)


gg <- ggplot()
# doing this vs y axis major grid line
gg <- gg + geom_segment(data=df, aes(y=test.names, yend=test.names, x=-1, xend=300), color="#b2b2b2", size=0.15)
# dum.dum.dum!bell
gg <- gg + geom_dumbbell(data=df, aes(y=test.names, x=mcGridAlive, xend=mcGridProp20kids),
                         size=1.5, color="#b2b2b2", point.size.l=3, point.size.r=3,
                         point.colour.l="#9fb059", point.colour.r="#edae52")

# text above points
gg <- gg + geom_text(data=df, aes(x=mcGridAlive, y=test.names, label=mcGridAlive), fontface="bold",
                     color="#9fb059", size=2.75, vjust=1)
gg <- gg + geom_text(data=df, color="#edae52", size=2.75, vjust=1,
                     aes(x=mcGridProp20kids, y=test.names, label=mcGridProp20kids), fontface="bold")

gg <- gg + scale_y_discrete(limits=df$test.names)

# difference column
gg <- gg + geom_text(data=df, aes(label=diff, y=test.names, x=305), fontface="bold", size=3)

gg <- gg + labs(title="Number of matching Replicates Within Each Test")
gg
```



## Discussion and Future Works 



## References
[1] D. Lang and D. Nolan, Data Science in R: A Case Studies Approach to Computation Reasoning and Problem Solving. New York, New York: CRC Press. 

[2] John Tsitsiklis, Christos Papadimitriou, and Pierre Humblet. The Performance of a
Precedence-Based Queuing Discipline. Journal of the Association for Computing Machinery ,
33:593–602, 1986.

[3] David Aldous and William Krebs. The ‘Birth-and-Assassination’ Process. Statistics and
Probability Letters, 10:427–430, 1990.
