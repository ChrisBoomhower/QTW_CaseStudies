---
title: "Real-Time Location System - Case Study Unit 6"
output: html_notebook
---

####Cory Adams, Chris Boomhower, Alexandra Fisher, Alex Frye
####MSDS 7333, October 11, 2017

##Abstract

This case study was undertaken in order to highlight and address the use of real-time location system (RTLS) technology and WiFi signals to predict the location of a device within a college dormitory. Location prediction is achieved by application of the k-nearest neighbors (kNN) clustering technique to a real location data set. Both a weighted and unweighted kNN are used and performance of the two classification methods on the data is then evaluated and compared against simple average predictions to determine the best prediction method. While prediction estimates for both models appear fairly close, we find the weighted kNN distance methodolgy to have the greatest impact and thus be the best method for location prediction. 

##Introduction

Real-time location systems (RTLS) are local systems comprised of tags, readers, and location sensing systems that function as a whole to accurately determine locations of people or objects in real-time. While GPS has become a ubiquitous solution for outdoor real-time locating, RTLS technology has evolved and become much more prevalent for indoor tracking. In this case study we investigate RTLS technology and the use of WiFi signals to predict location by applying k-nearest neighbors (kNN) to a real location data set. The data set used is comprised of MAC addresses from recorded connections made to routers within the college dormitory. WiFi signal strength is measured at every router (network access point) via a mobile scanning device, and by measuring signal strength for these routers at various locations we are able to create a reference dataset on which to base device position predictions.

Advanced clustering methods are then performed on the reference dataset through the application of weighted and unweighted kNN algorithms to predict device locations. This is accomplished by leveraging the kNN clustering technique to a set of signal strengths in which we average the known (x,y) values for these neighbors to predict location estimates of devices [1]. Alternatively, a weighted average is calculated and considered as a potentially better predictor. In this formulation, the weights are inversely proportional to the neighbors' distance (measured in Received Signal Strength Indication, or RSSI) from the test observation, allowing inclusion of the k points that are nearest while differentiating between them by how close they actually are [1]. After implementing the alternative approach of the weighted average kNN, resulting predictions are analyzed and compared against the simple, average predictions to ultimately determine the optimal prediction method. 

##Methods

The steps used for this analysis were: 1) data clean up and EDA; 2) signal strength analysis; 3) implementation of kNN average weighting approach; 4) implementation of kNN distance weighting approach; & 5) comparison of kNN approaches to determine the best location prediction method. Note that code used includes modified versions of R code function examples found in Data Science in R: A Case Studies Approach to Computational Reasoning and Problem Solving, Chapter 1, pages 3-40 [1]. 

####Data Import

For this case study we will use a dataset created by the University of Mannheim [1]. The "offline" dataset is an open-source dataset that can be found online at http://rdatasciencecases.org/Data/offline.final.trace.txt. This "offline" dataset will be used as the training dataset to build our prediction model. The dataset contains 146,080 data points and each data point consists of the following fields:

t = timestamp for each data point
id = MAC address of the device conducting the scan
pos = coordinates of the device conducting the scan
degree = orientation of the device conducting the scan
MACofResponse1 = MAC address of the first responding device
MACofResponseN = MAC address of the Nth responding device

Multiple devices can respond to the scanning device (MACofResponse1 to MACofResponseN) and each of the responding devices provide the following data:
  - SignalStrength (Decibel-milliwatts dBm)
  - Frequency
  - Mode (access point=3, adhoc mode=1)
  
The code below reads in the "offline" dataset and outputs some simple observations about how many lines in the file are data versus comments.

```{r}
# Configure number format to two decimal places only
options(digits = 2)

library(formattable)
library(lattice)
library(fields)

seed = 123

# Import offline data and explore data
txt = readLines("Data/offline.final.trace.txt")

paste("Total # of lines in offline data =",length(txt))
paste("Total # of comments in offline data =", sum(substr(txt, 1, 1) == "#")) #Check number of comment lines in offline data
paste("Total # of non-comment lines =", length(txt) - sum(substr(txt, 1, 1) == "#"))
```

####Adding Structure to the Data

This section of code allows us to manipulate the data with the goal of having it be easier to interpret and manage. Currently, the data is just a bunch of raw text lines with ";" separators between records.

The code below creates a function that allows us to iteratively create matrices for each line in the "offline" dataset and merge into a data frame we can begin to organize for analysis. All comments have been removed and the dataset is now represented as a data frame instead of raw text. The data frame is now 1,181,628 rows and 10 columns.

```{r}
lines = txt[ substr(txt, 1, 1) != "#" ]

# Following line expected to throw warnings since one of the positions contains no signal data; commenting out since this issue is addressed via the return(NULL) statement in the updated processLine function in this chunk
#tmp = lapply(lines, processLine)

processLine = function(x)
{
  tokens = strsplit(x, "[;=,]")[[1]]
  
  if (length(tokens) == 10) 
    return(NULL)
 
  tmp = matrix(tokens[ - (1:10) ], , 4, byrow = TRUE)
  cbind(matrix(tokens[c(2, 4, 6:8, 10)], nrow(tmp), 6, 
               byrow = TRUE), tmp)
}

options(error = recover, warn = 1)
tmp = lapply(lines, processLine)
offline = as.data.frame(do.call("rbind", tmp), 
                        stringsAsFactors = FALSE)

dim(offline)
```

####Cleaning the Data and Building a Representation for Analysis

In the previous section we cleaned the data and created a data frame named "offline" consisting of 1,181,628 rows and 10 columns. While the data is now organized, we must still remove unwanted/unnecessary rows, provide identifiable names to the variables, and convert the variable values to their proper type. At this point all the variables are represented as strings and our data clearly has several numerical values.

The code below provides a name for each of the 10 columns in the data frame and converts the time, position, and signal variables to numeric types. This is key for comparison and correlation of these variables. Since ad-hoc devices will not be used further, any rows with ad-hoc data are removed from the data frame. This also allows us to drop the type row since we now know all the types are access points. The output below demonstrates the data cleanup and variable conversions discussed. The result is 978,443 rows and 8 columns in our "offline" data frame.

```{r}
names(offline) = c("time", "scanMac", "posX", "posY", "posZ", 
                   "orientation", "mac", "signal", 
                   "channel", "type")

numVars = c("time", "posX", "posY", "posZ", 
            "orientation", "signal")
offline[ numVars ] =  lapply(offline[ numVars ], as.numeric)

offline = offline[ offline$type == "3", ]
offline = offline[ , "type" != names(offline) ]
dim(offline)

offline$rawTime = offline$time
offline$time = offline$time/1000
class(offline$time) = c("POSIXt", "POSIXct")

unlist(lapply(offline, class))

summary(offline[, numVars])

 summary(sapply(offline[ , c("mac", "channel", "scanMac")],
                as.factor))

offline = offline[ , !(names(offline) %in% c("scanMac", "posZ"))]
```

####EDA - Orientation

Prior to conducting analysis of our data frame, we must explore some of the key variables to better understand what they contain and how we can use them. The first variable we explore is the orientation variable.

A quick look at the unique values in the orientation column show there are 203 in total, although we were expecting only 8 (based on 45 degree increments). The Empirical CDF figure below shows that while the values are not strictly in 45 degree increments, they are close to one of the expected values as shown in the box plot figure below. This means that while they are not exact, they are close to a target orientation value. The code below takes the orientation value from each row and assigns it to the closest expected orientation value.

```{r}
length(unique(offline$orientation))

#pdf(file = "Geo_ECDFOrientation.pdf", width = 10, height = 7)
oldPar = par(mar = c(4, 4, 1, 1))
plot(ecdf(offline$orientation), pch = 19, cex = 0.3,
     xlim = c(-5, 365), axes = FALSE,
     xlab = "orientation", ylab = "Empirical CDF", main = "")
axis(2)
axis(side = 1, at = seq(0, 360, by = 45))
par(oldPar)
#dev.off()

# pdf(file = "Geo_DensityOrientation.pdf", width = 10, height = 5)
# oldPar = par(mar = c(4, 4, 1, 1))
# plot(density(offline$orientation, bw = 2), 
#  xlab = "orientation", main = "")
# par(oldPar)
# dev.off()

roundOrientation = function(angles) {
  refs = seq(0, by = 45, length  = 9)
  q = sapply(angles, function(o) which.min(abs(o - refs)))
  c(refs[1:8], 0)[q]
}

offline$angle = roundOrientation(offline$orientation)

#pdf(file = "Geo_BoxplotAngle.pdf", width = 10)
oldPar = par(mar = c(4, 4, 1, 1))
with(offline, boxplot(orientation ~ angle,
    xlab = "nearest 45 degree angle",
    ylab="orientation"))
par(oldPar)
#dev.off()
```

####EDA - MAC Addresses

The next key variable in the dataset we will explore is the MAC address. Analysis shows 12 MAC addresses, while the experiment design only called for and discussed 6 MAC addresseses on the network. The code below shows each MAC address and the number corresponding records. Clearly there is a large variance between MAC addresses with a high number of records versus MAC addresses with a low number of records. In this case, the top 7 MAC addresses were kept in the dataset and the rest were removed.

The code below shows that the unique identifier for the MAC address corresponds with the identifier for channel, meaning these two values are essentially the same in our analysis and only one is necessary. No statistical significance will be gained by keeping both and if anything this could lead to unwanted correlation between variables.

```{r}
c(length(unique(offline$mac)), length(unique(offline$channel)))

table(offline$mac)

subMacs = names(sort(table(offline$mac), decreasing = TRUE))[1:7]
offline = offline[ offline$mac %in% subMacs, ]

macChannel = with(offline, table(mac, channel))
apply(macChannel, 1, function(x) sum(x > 0))

offline = offline[ , "channel" != names(offline)]
```
####EDA - Hand-Held Device Position

The final variable we will explore is the position variable, or where the device was located within the experiment at the time of the data point. Each position variable recorded actually contains an X and Y value. The code below computes the total possible number of combinations for X and Y (476), checks if the values are null (310), and finally outputs non-null values (166). Knowing there are 166 positions where data was recorded, we can calculate the number of data points collected at each position. The matrix below shows the exact counts. While the number of data points per position are not equal, they are relatively close (~5,500). This means our data should not be biased by the position variable.

```{r}
locDF = with(offline, 
             by(offline, list(posX, posY), function(x) x))
length(locDF)


sum(sapply(locDF, is.null))

locDF = locDF[ !sapply(locDF, is.null) ]

length(locDF)

locCounts = sapply(locDF, nrow)

locCounts = sapply(locDF, 
                   function(df) 
                     c(df[1, c("posX", "posY")], count = nrow(df)))

class(locCounts)

dim(locCounts)

locCounts[ , 1:8]

#pdf(file = "Geo_XYByCount.pdf", width = 10)
oldPar = par(mar = c(3.1, 3.1, 1, 1))

locCounts = t(locCounts)
plot(locCounts, type = "n", xlab = "", ylab = "")
text(locCounts, labels = locCounts[,3], cex = .8, srt = 45)

par(oldPar)
#dev.off()
```

####Perform Cleanup as a Function

The previous steps (code blocks) provided clear instructions on how to read, structure, explore, and clean data from an external source.

Below is an optimized function (readData) that will allow us to download the same data and replicate the process shown above. The readData function below completes all the tasks shown in "Data Import", "Data Cleanup", "Cleaning the Data and Building a Representation for Analysis", "EDA - Orientation", "EDA - MAC Addresses", and "EDA - Hand-Held Device Position" efficiently. The output of this function results in the same dataset ("offline") as displayed by comparing the dataset output by the readData function ("offlineRedo"). The two datasets are identical, but this function is easier to update and deploy.

```{r}
readData = 
  function(filename = 'Data/offline.final.trace.txt', 
           subMacs = c("00:0f:a3:39:e1:c0", "00:0f:a3:39:dd:cd", "00:14:bf:b1:97:8a",
                       "00:14:bf:3b:c7:c6", "00:14:bf:b1:97:90", "00:14:bf:b1:97:8d",
                       "00:14:bf:b1:97:81"))
  {
    txt = readLines(filename)
    lines = txt[ substr(txt, 1, 1) != "#" ]
    tmp = lapply(lines, processLine)
    offline = as.data.frame(do.call("rbind", tmp), 
                            stringsAsFactors= FALSE) 
    
    names(offline) = c("time", "scanMac", 
                       "posX", "posY", "posZ", "orientation", 
                       "mac", "signal", "channel", "type")
    
     # keep only signals from access points
    offline = offline[ offline$type == "3", ]
    
    # drop scanMac, posZ, channel, and type - no info in them
    dropVars = c("scanMac", "posZ", "channel", "type")
    offline = offline[ , !( names(offline) %in% dropVars ) ]
    
    # drop more unwanted access points
    offline = offline[ offline$mac %in% subMacs, ]
    
    # convert numeric values
    numVars = c("time", "posX", "posY", "orientation", "signal")
    offline[ numVars ] = lapply(offline[ numVars ], as.numeric)

    # convert time to POSIX
    offline$rawTime = offline$time
    offline$time = offline$time/1000
    class(offline$time) = c("POSIXt", "POSIXct")
    
    # round orientations to nearest 45
    offline$angle = roundOrientation(offline$orientation)
      
    return(offline)
  }

offlineRedo = readData()

identical(offline, offlineRedo)
```

##Results

####Signal Strength Analysis - Distribution of Signal Strength

The variable we want to understand from this experiment is the signal strength. Is the signal strength consistent across distances? Is it significantly impacted by the other variables we collected?

We start by looking at the signal strength variable characteristics. The boxplot below shows the variance of the signal strength with multiple combinations of position and orientation. We also output a density plot to observe the variance of these combinations, as expected there is a mixture of normal and skewed distributions. A closer look at the variance between signal strength and position show something interesting, strong signals have a higher variance while weaker signals have a lower variance. This data was output using a summary of position, orientation, and access point combinations we will refer to as the "offlineSummary." 

```{r}
library(lattice)
bwplot(signal ~ factor(angle) | mac, data = offline, 
       subset = posX == 2 & posY == 12 
                & mac != "00:0f:a3:39:dd:cd", 
       layout = c(2,3))

par(oldPar)
#dev.off()

summary(offline$signal)

#pdf(file = "Geo_DensitySignalByMacAngle.pdf", width = 8, height = 12)
oldPar = par(mar = c(3.1, 3, 1, 1))

densityplot( ~ signal | mac + factor(angle), data = offline,
             subset = posX == 24 & posY == 4 & 
                         mac != "00:0f:a3:39:dd:cd",
             bw = 0.5, plot.points = FALSE)

par(oldPar)
#dev.off()

offline = offline[ offline$mac != "00:0f:a3:39:dd:cd", ]

offline$posXY = paste(offline$posX, offline$posY, sep = "-")

byLocAngleAP = with(offline, 
                    by(offline, list(posXY, angle, mac), 
                       function(x) x))

signalSummary = 
  lapply(byLocAngleAP,            
         function(oneLoc) {
           ans = oneLoc[1, ]
           ans$medSignal = median(oneLoc$signal)
           ans$avgSignal = mean(oneLoc$signal)
           ans$num = length(oneLoc$signal)
           ans$sdSignal = sd(oneLoc$signal)
           ans$iqrSignal = IQR(oneLoc$signal)
           ans
           })

offlineSummary = do.call("rbind", signalSummary)     

#pdf(file = "Geo_BoxplotSignalSDByAvg.pdf", width = 10)
oldPar = par(mar = c(3.1, 3, 1, 1))

breaks = seq(-90, -30, by = 5)
bwplot(sdSignal ~ cut(avgSignal, breaks = breaks),
       data = offlineSummary, 
       subset = mac != "00:0f:a3:39:dd:cd",
       xlab = "Mean Signal", ylab = "SD Signal")

par(oldPar)
#dev.off()

#pdf(file = "Geo_ScatterMean-Median.pdf", width = 10)
oldPar = par(mar = c(4.1, 4.1, 1, 1))

with(offlineSummary,
     smoothScatter((avgSignal - medSignal) ~ num,
                   xlab = "Number of Observations", 
                   ylab = "mean - median"))
abline(h = 0, col = "#984ea3", lwd = 2)

lo.obj = 
  with(offlineSummary,
       loess(diff ~ num, 
             data = data.frame(diff = (avgSignal - medSignal),
                               num = num)))

lo.obj.pr = predict(lo.obj, newdata = data.frame(num = (70:120)))
lines(x = 70:120, y = lo.obj.pr, col = "#4daf4a", lwd = 2)

par(oldPar)
#dev.off()
```

#### Relationship Between Signal and Distance

The code below begins by attempting to create a contour plot or heat map to help identify the actual areas of the floor plan where signals are stronger. To do this for each MAC address, orientation, and distance combination the summary statistic "offlineSummary", developed in the last section, is used. The heatmap below shows this contour plot for 2 MAC addresses and two orientations (0, 135). While the MAC address has never been associated with the location of the access point, we can use the contour plot to make inferences based on the floor plan.

Now that we are able to match the MAC/access point with the floor plan, we can investigate the relationship between the position variable and the signal strength. To show this we output a scatter plot using the distance and signal strength, along with each of the 8 developed orientations. The scatter plot seems to be similar across the combinations. 

```{r}
oneAPAngle = subset(offlineSummary, 
                    mac == subMacs[5] & angle == 0)


library(fields)
smoothSS = Tps(oneAPAngle[, c("posX","posY")], 
               oneAPAngle$avgSignal)

vizSmooth = predictSurface(smoothSS)

plot.surface(vizSmooth, type = "C")

points(oneAPAngle$posX, oneAPAngle$posY, pch=19, cex = 0.5)

surfaceSS = function(data, mac, angle = 45) {
  require(fields)
  oneAPAngle = data[ data$mac == mac & data$angle == angle, ]
  smoothSS = Tps(oneAPAngle[, c("posX","posY")], 
                 oneAPAngle$avgSignal)
  vizSmooth = predictSurface(smoothSS)
  plot.surface(vizSmooth, type = "C", 
               xlab = "", ylab = "", xaxt = "n", yaxt = "n")
  points(oneAPAngle$posX, oneAPAngle$posY, pch=19, cex = 0.5) 
}

parCur = par(mfrow = c(2,2), mar = rep(1, 4))

mapply(surfaceSS, mac = subMacs[ rep(c(5, 1), each = 2) ], 
       angle = rep(c(0, 135), 2),
       data = list(data = offlineSummary))
 
par(parCur)

offlineSummary = subset(offlineSummary, mac != subMacs[2])

AP = matrix( c( 7.5, 6.3, 2.5, -.8, 12.8, -2.8,  
                1, 14, 33.5, 9.3,  33.5, 2.8),
            ncol = 2, byrow = TRUE,
            dimnames = list(subMacs[ -2 ], c("x", "y") ))

AP

diffs = offlineSummary[ , c("posX", "posY")] - 
          AP[ offlineSummary$mac, ]

offlineSummary$dist = sqrt(diffs[ , 1]^2 + diffs[ , 2]^2)

xyplot(signal ~ dist | factor(mac) + factor(angle), 
       data = offlineSummary, pch = 19, cex = 0.3,
       xlab ="distance")

#pdf(file="Geo_ScatterSignalDist.pdf", width = 7, height = 10)
oldPar = par(mar = c(3.1, 3.1, 1, 1))
library(lattice)
xyplot(signal ~ dist | factor(mac) + factor(angle), 
       data = offlineSummary, pch = 19, cex = 0.3,
       xlab ="distance")
par(oldPar)
#dev.off()
```


####KNN Average Weighting
While there exist various techniques that may be used to estimate device location based on RSSI, this case study seeks to undertake a simple KNN clustering approach for test observation location determination. As such, a measure of Euclidean Distance, as depicted in the formula below, will be used to assess proximity of a test observation to the 166 potential neighbor locations:

<center>$Euclidean Distance =\sqrt{(S_1^*-S_1)^2 + ...+ (S_6^*-S_6)^2}$</center>


In this formula, $S_i$ represents the strength of a signal measured between a hand-held device and an $i$-th training observation access point recorded at a specific location. Similarly, $S_1^*$ represents the signal measured between the same access point and the new point under assessment whose $(x, y)$ coordinates we are interested in determining.

With much of our EDA complete and KNN prediction methodology defined, we need to next perform a few more preparatory actions before writing our model functions. Firstly, we create a unique location identifier column in our online data frame as follows.

```{r}
macs = unique(offlineSummary$mac)
online = readData("Data/online.final.trace.txt", subMacs = macs)

online$posXY = paste(online$posX, online$posY, sep = "-")

posXY.unique <- length(unique(online$posXY))
```

Based on the various X-Y combinations that have now been concatenated into a new column, we have ```r posXY.unique``` unique test locations available in the online dataset. With this in mind, we proceed to tally the number of RSSI values recorded at each location. The following output depicts 10 randomly sampled location tallies by orientation. This sampling reveals that RSSI values were recorded at only one orientation for each location.

```{r}
set.seed(seed = seed)
# Number of signal strengths recorded at each location
tabonlineXYA = table(online$posXY, online$angle)
tabonlineXYA[sample(1:nrow(tabonlineXYA), 10), ]
```

With these added insights, we are ready to restructure the data into 6 columns of signal strengths rather than only a single signal strength column with all access points as has been done so far. This means that each access point will have its own column comprised of its respective RSSI values. This step will make it easier to compute distance between the 6 signal strength vectors. In so doing, we provide the average signal strength at each location as summary and depict the first 10% of these below (the first 6 locations comprise the first 10%). Notice 11 columns are present in our summary, including the concatinated X-Y values, X and Y values in their separate columns, orientation, angle, and the 6 access points' average RSSI values.

```{r}
keepVars = c("posXY", "posX","posY", "orientation", "angle")
byLoc = with(online, 
             by(online, list(posXY), 
                function(x) {
                  ans = x[1, keepVars]
                  avgSS = tapply(x$signal, x$mac, mean)
                  y = matrix(avgSS, nrow = 1, ncol = 6,
                        dimnames = list(ans$posXY, names(avgSS)))
                  cbind(ans, y)
                }))

onlineSummary = do.call("rbind", byLoc)  

#dim(onlineSummary)
#names(onlineSummary)
head(onlineSummary)
```

As part of our prediction process, our objective is to find offline data points that share similar orientations to our new location points since we discovered orientation impacts signal strength during our EDA efforts. To accomplish this, we select all records within a particular range of the test point's orientation. As all observations were recorded in 45 degree increments, this becomes as easy as specifying the number of neighboring angles to include from the offline dataset. For even numbers, this means selecting even multiples of 45 degrees on each side of a test observation's orientation angle. For odd numbers, it means selecting offline data with angles which match the new observation's rounded orientation as well as those that flank the new observation's angle. In the case where only one orientation is desired, offline data with angles matching the new observation's will be selected only. The procedures to perform these actions, and to create a data structure aggregating the RSSI values from these angles, are as follows.

```{r}
reshapeSS = function(data, varSignal = "signal", 
                     keepVars = c("posXY", "posX","posY")) {
  byLocation =
    with(data, by(data, list(posXY), 
                  function(x) {
                    ans = x[1, keepVars]
                    avgSS = tapply(x[ , varSignal ], x$mac, mean)
                    y = matrix(avgSS, nrow = 1, ncol = 6,
                               dimnames = list(ans$posXY,
                                               names(avgSS)))
                    cbind(ans, y)
                  }))

  newDataSS = do.call("rbind", byLocation)
  return(newDataSS)
}


selectTrain = function(angleNewObs, signals = NULL, m = 1){
  # m is the number of angles to keep between 1 and 5
  refs = seq(0, by = 45, length  = 8)
  nearestAngle = roundOrientation(angleNewObs)
  
  if (m %% 2 == 1) 
    angles = seq(-45 * (m - 1) /2, 45 * (m - 1) /2, length = m)
  else {
    m = m + 1
    angles = seq(-45 * (m - 1) /2, 45 * (m - 1) /2, length = m)
    if (sign(angleNewObs - nearestAngle) > -1) 
      angles = angles[ -1 ]
    else 
      angles = angles[ -m ]
  }
  angles = angles + nearestAngle
  angles[angles < 0] = angles[ angles < 0 ] + 360
  angles[angles > 360] = angles[ angles > 360 ] - 360
  angles = sort(angles)
  
  offlineSubset = signals[ signals$angle %in% angles, ]
  reshapeSS(offlineSubset, varSignal = "avgSignal")
}
```

To illustrate the performance of the above functions, below we depict the data structure created for an angle of 130 degrees using 3 angles in total (only first 6 rows shown). This, therefore, is an aggregation for angles of 90, 135, and 180 degrees. Note the average signal strengths are computed for the different angles by the *selectTrain()* function and that one set of signal strengths is created for each of the offline dataset's ```r train130.nrow``` locations.

```{r}
train130 = selectTrain(130, offlineSummary, m = 3)

train130.nrow <- nrow(train130)

head(train130)
```

Once angle count functions are determined, the next step is to define a function to calculate distances between new points and all offline dataset observations. The following *findNN()* function is constructed to do just that, receiving 6 new signal strengths along with 6 offline signal strengths as output from the *selectTrain()* function. Locations of offline training observations are ordered by proximity to the new test observation's RSSI values before being output by *findNN()*.


```{r}
findNN = function(newSignal, trainSubset) {
  diffs = apply(trainSubset[ , 4:9], 1, 
                function(x) x - newSignal)
  dists = apply(diffs, 2, function(x) sqrt(sum(x^2)) )
  closest = order(dists)
  return(trainSubset[closest, 1:3 ])
}
```

As noted in our Methodology section, our first KNN prediction process simply averages the first k locations returned by the *findNN()* function. This procedure, along with the *findNN()*, *selectTrain()*, and *reshapeSS()* function calls, is embedded in the *predXY()* wrapper function as below.

*As indicated in our Methodology section, we will later be comparing the results of averaging the first k locations to weighting locations based on RSSI values.*

```{r}
predXY = function(newSignals, newAngles, trainData, 
                  numAngles = 1, k = 3){
  
  closeXY = list(length = nrow(newSignals))
  
  for (i in 1:nrow(newSignals)) {
    trainSS = selectTrain(newAngles[i], trainData, m = numAngles)
    closeXY[[i]] = 
      findNN(newSignal = as.numeric(newSignals[i, ]), trainSS)
  }

  estXY = lapply(closeXY, 
                 function(x) sapply(x[ , 2:3], 
                                    function(x) mean(x[1:k])))
  estXY = do.call("rbind", estXY)
  return(estXY)
}
```

Using the *predXY()* function, we illustrate location estimation accuracy for $k = 3$ and $k = 1$ KNN training counts. Furthermore, model fit is assessed by mapping actual and predicted locations with lines connecting the two points for each respective new observation. This map is first drawn for the 3-NN predictions below.

```{r}
estXYk3 = predXY(newSignals = onlineSummary[ , 6:11], 
                 newAngles = onlineSummary[ , 4], 
                 offlineSummary, numAngles = 3, k = 3)

estXYk1 = predXY(newSignals = onlineSummary[ , 6:11], 
                 newAngles = onlineSummary[ , 4], 
                 offlineSummary, numAngles = 3, k = 1)

floorErrorMap = function(estXY, actualXY, trainPoints = NULL, AP = NULL){
  
    plot(0, 0, xlim = c(0, 35), ylim = c(-3, 15), type = "n",
         xlab = "", ylab = "", axes = FALSE)
    box()
    if ( !is.null(AP) ) points(AP, pch = 15)
    if ( !is.null(trainPoints) )
      points(trainPoints, pch = 19, col="grey", cex = 0.6)
    
    points(x = actualXY[, 1], y = actualXY[, 2], 
           pch = 19, cex = 0.8 )
    points(x = estXY[, 1], y = estXY[, 2], 
           pch = 8, cex = 0.8 )
    segments(x0 = estXY[, 1], y0 = estXY[, 2],
             x1 = actualXY[, 1], y1 = actualXY[ , 2],
             lwd = 2, col = "red")
}

trainPoints = offlineSummary[ offlineSummary$angle == 0 & 
                              offlineSummary$mac == "00:0f:a3:39:e1:c0" ,
                        c("posX", "posY")]

#pdf(file="GEO_FloorPlanK3Errors.pdf", width = 10, height = 7)
oldPar = par(mar = c(1, 1, 1, 1))
floorErrorMap(estXYk3, onlineSummary[ , c("posX","posY")], 
              trainPoints = trainPoints, AP = AP)
```

The same is then done for the 1-NN predictions next. Note that upon comparison, errors are generally smaller for the 3-NN model than they are for 1-NN and that the largest errors tend to follow hallways rather than traverse large obstacles such as walls or other stationary barriers.

```{r}
floorErrorMap(estXYk1, onlineSummary[ , c("posX","posY")], 
              trainPoints = trainPoints, AP = AP)
par(oldPar)
```

As further and more concrete assessment, we assess fits from the 3-NN and 1-NN models by comparing their Sum of Squared Error (SSE) values as follows.

```{r}
calcError = 
function(estXY, actualXY) 
   sum( rowSums( (estXY - actualXY)^2) )

actualXY = onlineSummary[ , c("posX", "posY")]
SSE <- sapply(list(estXYk1, estXYk3), calcError, actualXY)
```

Doing so reveals $k_1 SSE =$```r SSE[1]``` and $k_3 SSE =$ ```r SSE[2]```. This correlates with the visual summary we extracted from the error maps above and confirms that 3 nearest neighbors more accurately predict location when compred to only one nearest neighbor. Even so, we still need to determine if there is another k value that would even more accurately predict device location.

In order to avoid overfitting, we must identify the optimal value of k independent of our test observations. We use v-fold cross validation to do so. A $v$ value of 11 is selected since we have 166 different offline locations, allocating 15 locations to each fold. Allocations are randomly selected as follows (Note a warning is received since a $v$ of 11 does not divide evenly into 166; this is acceptable in our case).

```{r}
set.seed(seed = seed)

v = 11
permuteLocs = sample(unique(offlineSummary$posXY))
permuteLocs = matrix(permuteLocs, ncol = v, 
                     nrow = floor(length(permuteLocs)/v))

onlineFold = subset(offlineSummary, posXY %in% permuteLocs[ , 1])
```

After performing the above random allocations, the first 6 of ```r onlineFold.ul``` locations from our first fold are depicted below.

```{r}
head(onlineFold)
onlineFold.ul <- nrow(unique(onlineFold[,2:3]))
```

Since we previously summarized our offline data into a structure containing 6 signal strength columns, one for each access point, we will do the same with our cross-validated test data. However, because it is easier to structure the test data in its complete form from offline data which is then divided into our desired folds, we now need to modify the *reshapeSS()* function as follows.

```{r}
reshapeSS = function(data, varSignal = "signal", 
                     keepVars = c("posXY", "posX","posY"),
                     sampleAngle = FALSE, 
                     refs = seq(0, 315, by = 45)) {
    
  set.seed(seed = seed)
    
  byLocation =
    with(data, by(data, list(posXY), 
                  function(x) {
                    if (sampleAngle) { # conditional statement added for cross-validation
                      x = x[x$angle == sample(refs, size = 1), ]}
                    ans = x[1, keepVars]
                    avgSS = tapply(x[ , varSignal ], x$mac, mean)
                    y = matrix(avgSS, nrow = 1, ncol = 6,
                               dimnames = list(ans$posXY,
                                               names(avgSS)))
                    cbind(ans, y)
                  }))

  newDataSS = do.call("rbind", byLocation)
  return(newDataSS)
}
```

We now proceed to summarize and format the offline data using the updated *reshapeSS()* function to produce our online cross-validation summary data structure as below.

```{r}
offline = offline[ offline$mac != "00:0f:a3:39:dd:cd", ] #Look at all but MAC 00:0f:a3:39:dd:cd

keepVars = c("posXY", "posX","posY", "orientation", "angle")

onlineCVSummary = reshapeSS(offline, keepVars = keepVars, 
                            sampleAngle = TRUE)
```

We're now finally ready to determine the appropriate value for k based on our data. To do this, we calculate the SSE values for each value of k between 1 and 20. Doing this allows us to choose the k value which produces the smallest error among all k options.

```{r}
K = 20
err = rep(0, K)

for (j in 1:v) {
  onlineFold = subset(onlineCVSummary, 
                      posXY %in% permuteLocs[ , j])
  offlineFold = subset(offlineSummary,
                       posXY %in% permuteLocs[ , -j])
  actualFold = onlineFold[ , c("posX", "posY")]
  
  for (k in 1:K) {
    estFold = predXY(newSignals = onlineFold[ , 6:11],
                     newAngles = onlineFold[ , 4], 
                     offlineFold, numAngles = 3, k = k)
    err[k] = err[k] + calcError(estFold, actualFold)
  }
}
```

The SSE values produced for $k = 1$ through $k = 20$ are plotted for quick and easy review. The below figure plots the sum of fold SSE values with respect to each k count.

```{r}
oldPar = par(mar = c(4, 5, 1, 1))
plot(y = err, x = (1:K),  type = "l", lwd= 2,
     ylim = c(1200, 2100),
     xlab = "Number of Neighbors",
     ylab = "Sum of Square Errors")

rmseMin = min(err)
kMin = which(err == rmseMin)[1]
segments(x0 = 0, x1 = kMin, y0 = rmseMin, col = gray(0.4), 
         lty = 2, lwd = 2)
segments(x0 = kMin, x1 = kMin, y0 = 1100,  y1 = rmseMin, 
         col = grey(0.4), lty = 2, lwd = 2)

mtext(kMin, side = 1, line = 1, at = kMin, col = grey(0.4))
text(x = kMin - 2, y = rmseMin + 40, 
     label = as.character(round(rmseMin)), col = grey(0.4))
par(oldPar)
```

Based on our analysis, $k =$ ```r kMin``` produces the least amount of error. This value differs from Nolan and Lang's $k=5$ identified in their case study walkthrough due to our random sampling during *offlineSummary*, *onlineCVSummary*, and *permuteLocs* computation. Had we been provided the same seed value they used during their analysis, we would have obtained the same k result. However, since the difference is due to randomness alone, our $k=$ ```r kMin``` is perfectly acceptable. With our optimal k defined, we may proceed with estimation to calculate final Sum of Squared Errors.

```{r}
estXYk4 = predXY(newSignals = onlineSummary[ , 6:11], 
                 newAngles = onlineSummary[ , 4], 
                 offlineSummary, numAngles = 3, k = kMin)

SSE.k4 <- calcError(estXYk4, actualXY)
```

Based on these results, $k_4 SSE =$```r SSE.k4```. This value is less than our previous reviews of $k_1 SSE$ and $k_3 SSE$ at ```r SSE[1]``` and ```r SSE[2]``` respectively. As expected, choosing an optimized value for k results in the most accurate model. It is this SSE value for $k=4$, ```r SSE.k4```, that we will use to compare against our weighted distance KNN model.

####KNN Distance Weighting

As we estimate position by average x,y location across k nearest points, we begin to wonder if the distance of those points is relevant to the accuracy of the model. To test this, we apply weights to the x,y positions of each k closest locations and take the sum of those results, instead of averaging the values. With the below formula, we are able to compute weights for each k closest observations.

$$
\begin{aligned}
\frac{1/d_i}{\sum_{i=1}^{k}1/d_i}
\end{aligned}
$$

The findNN function below has been modified from the previous version to also output the distance metrics utilized in determining the "closest" k points. Additionally, the predXY function has been modified to compute weights with the formula above and distance outputs from the findNN output. These weights are then multiplied against each k nearest observation, respectively, then summed, to compute a weighted estimation by distance. These new calculations may allow locations of closer distances, to be more impactful than those further away instead of equal weighting amongst the k points.

```{r}

#Modify findNN to also output the distances
findNN = function(newSignal, trainSubset) {
  diffs = apply(trainSubset[ , 4:9], 1, 
                function(x) x - newSignal)
  dists = apply(diffs, 2, function(x) sqrt(sum(x^2)) )
  closest = order(dists)
  return(list(trainSubset[closest, 1:3 ],dists[order(dists)]))
}

#Modify findNN to utilize distance output for estimation efforts
predXY = function(newSignals, newAngles, trainData, 
                  numAngles = 1, k = 3){
  
  closeXY = list(length = nrow(newSignals))
  closeDist = list(length = nrow(newSignals))
  
  for (i in 1:nrow(newSignals)) {
    trainSS = selectTrain(newAngles[i], trainData, m = numAngles)
    fnnResult =
    findNN(newSignal = as.numeric(newSignals[i, ]), trainSS)
  
    closeXY[[i]] = fnnResult[[1]]
    closeDist[[i]] = fnnResult[[2]]
  }
  
  
  distWeight = list(length = length(closeDist))
  
  for (i in 1:length(closeDist)){
    distW = list(length = k)

    for (j in 1:k){
      distW[j] = (1/closeDist[[i]][j])/sum(1/closeDist[[i]][1:k])
    }
     
    distWeight[[i]] =  distW
  }

  estXYDetails = list(length=length(closeXY))
  
  for(i in 1:length(closeXY)){
    estXYDetails[[i]] = as.matrix(closeXY[[i]][1:k,2:3]) * unlist(distWeight[[i]])
  }
  

  estXY = lapply(estXYDetails,
                 function(x) apply(x, 2,
                                   function(x) sum(x)))
  
  
  estXY = do.call("rbind", estXY)
  return(estXY)
}
```


```{r}
set.seed(seed = seed)

K = 20
err = rep(0, K)

for (j in 1:v) {
  onlineFold = subset(onlineCVSummary, 
                      posXY %in% permuteLocs[ , j])
  offlineFold = subset(offlineSummary,
                       posXY %in% permuteLocs[ , -j])
  actualFold = onlineFold[ , c("posX", "posY")]
  
  for (k in 1:K) {
    estFold = predXY(newSignals = onlineFold[ , 6:11],
                     newAngles = onlineFold[ , 4], 
                     offlineFold, numAngles = 3, k = k)
    err[k] = err[k] + calcError(estFold, actualFold)
  }
}
```

Once again, we perform fold tests on 1-20 k nearest neighbor estimations. This time, utilizing the distance weighting modifications for each estimation. We save errors computed in each k iteration, so we may plot results below. 

```{r}
set.seed(seed = seed)

oldPar = par(mar = c(4, 5, 1, 1))
plot(y = err, x = (1:K),  type = "l", lwd= 2,
     ylim = c(1200, 2100),
     xlab = "Number of Neighbors",
     ylab = "Sum of Square Errors")

rmseMin = min(err)
kMin = which(err == rmseMin)[1]
segments(x0 = 0, x1 = kMin, y0 = rmseMin, col = gray(0.4), 
         lty = 2, lwd = 2)
segments(x0 = kMin, x1 = kMin, y0 = 900,  y1 = rmseMin, 
         col = grey(0.4), lty = 2, lwd = 2)

mtext(kMin, side = 1, line = 1, at = kMin, col = grey(0.4))
text(x = kMin - 2, y = rmseMin + 40, 
     label = as.character(round(rmseMin)), col = grey(0.4))
par(oldPar)
```


Plotting SSE values amongst the 20 k test iterations, we see that $kmin =$ ```r kMin``` produces optimal results at a an SSE value of `r err[kMin]`

```{r}
set.seed(seed = seed)

estXYk8 = predXY(newSignals = onlineSummary[ , 6:11], 
                 newAngles = onlineSummary[ , 4], 
                 offlineSummary, numAngles = 3, k = kMin)

SSE.k8 <- calcError(estXYk8, actualXY)

```

With our optimal $k$ value selected for number of nearest points, we compute predictions utilizing the weighted distance estimation method storing the SSE values for comparison to the average location methods.

####KNN Comparison

With optimal predition method inputs defined for both average location estimation and weighted distance estimation, we compare estimations both visually and through SSE values.
As can be seen below, Average Location Estimates vs Actual(top) and Weighted Distance Estimates vs Actual(bottom) plots help to describe how accurate the estimations were. Errors in both models, seem to struggle the most in narrow hallways. This large error makes sense, given the fewer observations available for $k$ matches. OVerall, differences in these output show very similar results with some errors being largely minimized by the weighted distance strategy and others slightly increased. Although these measures appear fairly close to one another, it does appear as though the weighted distance methodology overall has a greater impact. 

```{r}
oldPar = par(mar = c(1, 1, 1, 1))
par(oldPar)
floorErrorMap(estXYk4, onlineSummary[ , c("posX","posY")], 
              trainPoints = trainPoints, AP = AP)

oldPar = par(mar = c(1, 1, 1, 1))
par(oldPar)
floorErrorMap(estXYk8, onlineSummary[ , c("posX","posY")], 
              trainPoints = trainPoints, AP = AP)
```


Our observations in the above visuals may be confirmed by comparing SSE values for each method. $k_{8WeightedDistance}SSE =$```r SSE.k8``` through weighted distance estimation is `r abs(SSE.k8 - SSE.k4)` less than our previous reviews of $k_{4AverageLocation}SSE$ at ```r SSE.k4``` from the mean location nearest neighbor estimation. This places our original observations from the visuals correct, with the weighted distance estimation providing more accurate results overall in the model. These weighted distances allow those $k$ observations that are heavily skewed with few observations of close distance and large number of observations of large distance to be appropriately computed without biased input from the further distance points. 

##Discussion and Future Works


## References
[1] D. Lang and D. Nolan, Data Science in R: A Case Studies Approach to Computation Reasoning and Problem Solving. New York, New York: CRC Press.  
